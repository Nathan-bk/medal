{"cells":[{"cell_type":"code","execution_count":24,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1895,"status":"ok","timestamp":1649848996158,"user":{"displayName":"nathan bigaud","userId":"12543085100510385482"},"user_tz":-120},"id":"cfXeUfdDN3JQ","outputId":"d61cc39a-9f3d-46ee-f69f-9e5c30018a8b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":25,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1649848997627,"user":{"displayName":"nathan bigaud","userId":"12543085100510385482"},"user_tz":-120},"id":"T1Sld3r8PXti","outputId":"0a111d04-06bb-446d-897a-37eef82252df"},"outputs":[{"output_type":"stream","name":"stdout","text":["[Errno 2] No such file or directory: 'drive/MyDrive/work/S2/NLP/medal'\n","/content/drive/MyDrive/work/S2/NLP/medal\n"]}],"source":["#Nathan's path\n","%cd drive/MyDrive/work/S2/NLP/medal\n","\n","#Someone else's path\n","#%cd /content/drive/MyDrive/Dauphine/M2/S2/NLP/medal"]},{"cell_type":"code","execution_count":26,"metadata":{"executionInfo":{"elapsed":3043,"status":"ok","timestamp":1649849001022,"user":{"displayName":"nathan bigaud","userId":"12543085100510385482"},"user_tz":-120},"id":"DlWa6hNrPtL6"},"outputs":[],"source":["%pip install transformers fasttext -q"]},{"cell_type":"markdown","metadata":{"id":"gcUKdoY_PDj3"},"source":["## Pre-training"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8HaEudgBmhid"},"outputs":[],"source":["ARGS = {\n","    \"savedir\":\"./csv_logs\",\n","    \"model\":\"electra\",\n","    \"data_dir\":\"./data/pretraining\",\n","    \"data_filename\":\"medal.csv\",\n","    \"adam_path\":\"./toy_data/valid_adam.txt\",\n","    \"embs_path\":\"./data\",\n","    \"use_scheduler\":True,\n","    \"lr\":2e-6,\n","    \"clip\":0,\n","    \"dropout\":0.1,\n","    \"epochs\":10,\n","    \"accum_num\":1,\n","    \"save_every\":1,\n","    \"eval_every\":200000,\n","    \"batchsize\":8,\n","    \"hidden_size\":512,\n","    \"rnn_layers\":3,\n","    \"da_layers\":1,\n","    \"pretrained_model\": \"./models/electra.pt\"\n","    }"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3XMEzvMMPK89"},"outputs":[],"source":["import argparse\n","import os\n","import time\n","import pandas as pd\n","\n","import torch\n","import torch.optim as optim\n","from torch import nn\n","\n","from models.rnn import RNN\n","from models.lstm_sa import RNNAtt\n","from models.electra import Electra\n","from transformers import ElectraTokenizer\n","from utils import load_dataframes, load_model, train_loop\n","from models.tokenizer_and_dataset import \\\n","    FastTextTokenizer, EmbeddingsDataset, HuggingfaceDataset\n","\n","from torch.utils.tensorboard import SummaryWriter\n","\n","EXPERIMENT_DIR = ARGS.get('savedir')\n","N_EPOCHS = ARGS.get('get('epochs')\n","BATCH_SIZE = ARGS.get('batchsize')\n","N_CPU_CORES = ARGS.get('ncpu')\n","MODEL_TYPE = ARGS.get('model')\n","USE_PRETRAIN = True\n","\n","DEVICE = torch.device(f\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# Load data\n","\n","train, valid, test, label_to_ix = load_dataframes (\n","                                    data_dir=ARGS.get('data_dir'), \n","                                    data_filename=ARGS.get('data_filename'),\n","                                    adam_path=ARGS.get('adam_path')\n","                                    )\n","print(\"Data loaded\")\n","\n","# Create tokenizer objects\n","if MODEL_TYPE == \"electra\":\n","    tokenizer = ElectraTokenizer.from_pretrained('google/electra-small-discriminator')\n","else:\n","    # Create word index and load Fasttext embedding matrix\n","    tokenizer = FastTextTokenizer(verbose=True)\n","    tokenizer.build_word_index(train.TEXT, valid.TEXT, test.TEXT, list(label_to_ix.keys()))\n","    tokenizer.build_embedding_matrix(ARGS.get('embs_path'))\n","\n","# Create torch Dataset objects\n","if MODEL_TYPE == \"electra\":\n","    train_data = HuggingfaceDataset(train, tokenizer=tokenizer, device=DEVICE)\n","    valid_data = HuggingfaceDataset(valid, tokenizer=tokenizer, device=DEVICE)\n","else:\n","    train_data = EmbeddingsDataset(train, tokenizer=tokenizer, device=DEVICE)\n","    valid_data = EmbeddingsDataset(valid, tokenizer=tokenizer, device=DEVICE)\n","print(\"Dataset created\")\n","\n","# Define network, loss function and optimizer\n","\n","net = Electra(\n","        output_size=len(label_to_ix),\n","        device=DEVICE,\n","    )\n","print('model: {}'.format(net))\n","\n","\n","if torch.cuda.device_count() > 1:\n","    net.to(DEVICE)\n","    print(\"Using\", torch.cuda.device_count(), \"GPUs\")\n","    net = nn.DataParallel(net)\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(net.parameters(), ARGS.get('lr'))\n","scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.2, patience=8) \\\n","    if ARGS.get('use_scheduler') else None\n","\n","# Create save directory\n","time_stamp = time.strftime(\"%m-%d-%H-%M\", time.localtime())\n","save_dir = os.path.join(EXPERIMENT_DIR, time_stamp)\n","if not os.path.exists(save_dir):\n","    os.makedirs(save_dir)\n","\n","# Save configs\n","model_desc_output = [\": \".join([str(k), str(v)]) for k, v in ARGS.items()]\n","with open(os.path.join(save_dir, 'configs.txt'), 'w') as file:\n","    file.writelines(\"\\n\".join(model_desc_output))\n","\n","# Set up tensorboard\n","writer = SummaryWriter(f\"runs/{MODEL_TYPE}-{time_stamp}\")\n","\n","# Train network\n","net, logs = train_loop(\n","    net, MODEL_TYPE, optimizer, criterion, train_data, valid_data, save_dir=save_dir, n_epochs=N_EPOCHS, \\\n","        batch_size=BATCH_SIZE, verbose=True, scheduler=scheduler, save_every=ARGS.get('save_every'), \\\n","        eval_every=ARGS.get('eval_every'), clip=ARGS.get('clip'), writer=writer, accum_num=ARGS.get('accum_num'),\n",")\n","\n","# Save Model\n","torch.save(net, os.path.join(save_dir, 'model.pt'))\n","\n","# Save Logs\n","log_df = pd.DataFrame(logs)\n","log_df.to_csv(os.path.join(save_dir, 'logs.csv'))\n"]},{"cell_type":"markdown","metadata":{"id":"_EFBsduJmspi"},"source":["## Mortality prediction"]},{"cell_type":"code","execution_count":47,"metadata":{"executionInfo":{"elapsed":322,"status":"ok","timestamp":1649850188683,"user":{"displayName":"nathan bigaud","userId":"12543085100510385482"},"user_tz":-120},"id":"j2LPuLyBmy_x"},"outputs":[],"source":["import multiprocessing\n","CORES = multiprocessing.cpu_count() # Count the number of cores in a computer\n","\n","ARGS = {\n","    \"savedir\":\"./csv_logs\",\n","    \"model\":\"electra\",\n","    \"data_dir\":\"./data/downstream\",\n","    \"data_filename\":\"mimic.csv\",\n","    \"adam_path\":\"./toy_data/valid_adam.txt\",\n","    \"embs_path\":\"./data\",\n","    \"task\":\"mimic-mortality\",\n","    \"use_scheduler\":True,\n","    \"lr\":2e-6,\n","    \"clip\":0,\n","    \"dropout\":0.1,\n","    \"epochs\":3,\n","    \"save_every\":1,\n","    \"eval_every\":10000,\n","    \"batchsize\":8,\n","    \"hidden_size\":512,\n","    \"da_layers\":1,\n","    \"ncpu\":CORES\n","    }\n","#,\"pretrained_model\": \"./models/electra.pt\""]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5tDi3CoVOMQE","outputId":"e1244b3c-8530-4f2a-a1a0-ffa468b80c73"},"outputs":[{"output_type":"stream","name":"stdout","text":["No pretrained model provided. Will train from scratch.\n","Data loaded\n","Dataset created\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at google/electra-small-discriminator were not used when initializing ElectraModel: ['discriminator_predictions.dense.bias', 'discriminator_predictions.dense_prediction.bias', 'discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense.weight']\n","- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["model: Electra(\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (electra): ElectraModel(\n","    (embeddings): ElectraEmbeddings(\n","      (word_embeddings): Embedding(30522, 128, padding_idx=0)\n","      (position_embeddings): Embedding(512, 128)\n","      (token_type_embeddings): Embedding(2, 128)\n","      (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (embeddings_project): Linear(in_features=128, out_features=256, bias=True)\n","    (encoder): ElectraEncoder(\n","      (layer): ModuleList(\n","        (0): ElectraLayer(\n","          (attention): ElectraAttention(\n","            (self): ElectraSelfAttention(\n","              (query): Linear(in_features=256, out_features=256, bias=True)\n","              (key): Linear(in_features=256, out_features=256, bias=True)\n","              (value): Linear(in_features=256, out_features=256, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): ElectraSelfOutput(\n","              (dense): Linear(in_features=256, out_features=256, bias=True)\n","              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): ElectraIntermediate(\n","            (dense): Linear(in_features=256, out_features=1024, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): ElectraOutput(\n","            (dense): Linear(in_features=1024, out_features=256, bias=True)\n","            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): ElectraLayer(\n","          (attention): ElectraAttention(\n","            (self): ElectraSelfAttention(\n","              (query): Linear(in_features=256, out_features=256, bias=True)\n","              (key): Linear(in_features=256, out_features=256, bias=True)\n","              (value): Linear(in_features=256, out_features=256, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): ElectraSelfOutput(\n","              (dense): Linear(in_features=256, out_features=256, bias=True)\n","              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): ElectraIntermediate(\n","            (dense): Linear(in_features=256, out_features=1024, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): ElectraOutput(\n","            (dense): Linear(in_features=1024, out_features=256, bias=True)\n","            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): ElectraLayer(\n","          (attention): ElectraAttention(\n","            (self): ElectraSelfAttention(\n","              (query): Linear(in_features=256, out_features=256, bias=True)\n","              (key): Linear(in_features=256, out_features=256, bias=True)\n","              (value): Linear(in_features=256, out_features=256, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): ElectraSelfOutput(\n","              (dense): Linear(in_features=256, out_features=256, bias=True)\n","              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): ElectraIntermediate(\n","            (dense): Linear(in_features=256, out_features=1024, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): ElectraOutput(\n","            (dense): Linear(in_features=1024, out_features=256, bias=True)\n","            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): ElectraLayer(\n","          (attention): ElectraAttention(\n","            (self): ElectraSelfAttention(\n","              (query): Linear(in_features=256, out_features=256, bias=True)\n","              (key): Linear(in_features=256, out_features=256, bias=True)\n","              (value): Linear(in_features=256, out_features=256, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): ElectraSelfOutput(\n","              (dense): Linear(in_features=256, out_features=256, bias=True)\n","              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): ElectraIntermediate(\n","            (dense): Linear(in_features=256, out_features=1024, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): ElectraOutput(\n","            (dense): Linear(in_features=1024, out_features=256, bias=True)\n","            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): ElectraLayer(\n","          (attention): ElectraAttention(\n","            (self): ElectraSelfAttention(\n","              (query): Linear(in_features=256, out_features=256, bias=True)\n","              (key): Linear(in_features=256, out_features=256, bias=True)\n","              (value): Linear(in_features=256, out_features=256, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): ElectraSelfOutput(\n","              (dense): Linear(in_features=256, out_features=256, bias=True)\n","              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): ElectraIntermediate(\n","            (dense): Linear(in_features=256, out_features=1024, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): ElectraOutput(\n","            (dense): Linear(in_features=1024, out_features=256, bias=True)\n","            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): ElectraLayer(\n","          (attention): ElectraAttention(\n","            (self): ElectraSelfAttention(\n","              (query): Linear(in_features=256, out_features=256, bias=True)\n","              (key): Linear(in_features=256, out_features=256, bias=True)\n","              (value): Linear(in_features=256, out_features=256, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): ElectraSelfOutput(\n","              (dense): Linear(in_features=256, out_features=256, bias=True)\n","              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): ElectraIntermediate(\n","            (dense): Linear(in_features=256, out_features=1024, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): ElectraOutput(\n","            (dense): Linear(in_features=1024, out_features=256, bias=True)\n","            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): ElectraLayer(\n","          (attention): ElectraAttention(\n","            (self): ElectraSelfAttention(\n","              (query): Linear(in_features=256, out_features=256, bias=True)\n","              (key): Linear(in_features=256, out_features=256, bias=True)\n","              (value): Linear(in_features=256, out_features=256, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): ElectraSelfOutput(\n","              (dense): Linear(in_features=256, out_features=256, bias=True)\n","              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): ElectraIntermediate(\n","            (dense): Linear(in_features=256, out_features=1024, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): ElectraOutput(\n","            (dense): Linear(in_features=1024, out_features=256, bias=True)\n","            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): ElectraLayer(\n","          (attention): ElectraAttention(\n","            (self): ElectraSelfAttention(\n","              (query): Linear(in_features=256, out_features=256, bias=True)\n","              (key): Linear(in_features=256, out_features=256, bias=True)\n","              (value): Linear(in_features=256, out_features=256, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): ElectraSelfOutput(\n","              (dense): Linear(in_features=256, out_features=256, bias=True)\n","              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): ElectraIntermediate(\n","            (dense): Linear(in_features=256, out_features=1024, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): ElectraOutput(\n","            (dense): Linear(in_features=1024, out_features=256, bias=True)\n","            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): ElectraLayer(\n","          (attention): ElectraAttention(\n","            (self): ElectraSelfAttention(\n","              (query): Linear(in_features=256, out_features=256, bias=True)\n","              (key): Linear(in_features=256, out_features=256, bias=True)\n","              (value): Linear(in_features=256, out_features=256, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): ElectraSelfOutput(\n","              (dense): Linear(in_features=256, out_features=256, bias=True)\n","              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): ElectraIntermediate(\n","            (dense): Linear(in_features=256, out_features=1024, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): ElectraOutput(\n","            (dense): Linear(in_features=1024, out_features=256, bias=True)\n","            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): ElectraLayer(\n","          (attention): ElectraAttention(\n","            (self): ElectraSelfAttention(\n","              (query): Linear(in_features=256, out_features=256, bias=True)\n","              (key): Linear(in_features=256, out_features=256, bias=True)\n","              (value): Linear(in_features=256, out_features=256, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): ElectraSelfOutput(\n","              (dense): Linear(in_features=256, out_features=256, bias=True)\n","              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): ElectraIntermediate(\n","            (dense): Linear(in_features=256, out_features=1024, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): ElectraOutput(\n","            (dense): Linear(in_features=1024, out_features=256, bias=True)\n","            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): ElectraLayer(\n","          (attention): ElectraAttention(\n","            (self): ElectraSelfAttention(\n","              (query): Linear(in_features=256, out_features=256, bias=True)\n","              (key): Linear(in_features=256, out_features=256, bias=True)\n","              (value): Linear(in_features=256, out_features=256, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): ElectraSelfOutput(\n","              (dense): Linear(in_features=256, out_features=256, bias=True)\n","              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): ElectraIntermediate(\n","            (dense): Linear(in_features=256, out_features=1024, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): ElectraOutput(\n","            (dense): Linear(in_features=1024, out_features=256, bias=True)\n","            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): ElectraLayer(\n","          (attention): ElectraAttention(\n","            (self): ElectraSelfAttention(\n","              (query): Linear(in_features=256, out_features=256, bias=True)\n","              (key): Linear(in_features=256, out_features=256, bias=True)\n","              (value): Linear(in_features=256, out_features=256, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): ElectraSelfOutput(\n","              (dense): Linear(in_features=256, out_features=256, bias=True)\n","              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): ElectraIntermediate(\n","            (dense): Linear(in_features=256, out_features=1024, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): ElectraOutput(\n","            (dense): Linear(in_features=1024, out_features=256, bias=True)\n","            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","  )\n","  (cls_att): AttentionModule(\n","    (dropout): Dropout(p=0.1, inplace=False)\n","  )\n","  (output): Linear(in_features=256, out_features=1, bias=True)\n",")\n","Datasets created:\n","\n","Training set: 204811 samples\n","\n","Validation set: 28019 samples\n","\n","Start training\n","\n"]},{"output_type":"stream","name":"stderr","text":["\r  0%|          | 0/25602 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n","  0%|          | 124/25602 [00:29<1:36:52,  4.38it/s]"]}],"source":["import os\n","import time\n","import sys\n","\n","import torch\n","import torch.optim as optim\n","from torch import nn\n","from torch.utils.data import DataLoader\n","\n","from transformers import ElectraTokenizer\n","from downstream.utils import load_mimic_mortality, load_mimic_diagnosis, load_model, predict, evaluate, train_loop\n","from downstream.electra import Electra\n","import pandas as pd\n","import numpy as np\n","\n","from downstream.tokenizer_and_dataset import FastTextTokenizer, MimicDataset, HuggingfaceDataset\n","\n","from torch.utils.tensorboard import SummaryWriter\n","\n","\n","EXPERIMENT_DIR = ARGS.get('savedir')\n","N_EPOCHS = ARGS.get('epochs')\n","BATCH_SIZE = ARGS.get('batchsize')\n","N_CPU_CORES = ARGS.get('ncpu')\n","MODEL_TYPE = ARGS.get('model')\n","TASK = ARGS.get('task')\n","TEST = ARGS.get('test')\n","USE_PRETRAIN = True if ARGS.get('pretrained_model') else False\n","\n","if TEST and not USE_PRETRAIN:\n","    raise Exception(\"no model preovided for testing\")\n","\n","if not USE_PRETRAIN:\n","    print(\"No pretrained model provided. Will train from scratch.\")\n","\n","# Prelim\n","torch.set_num_threads(N_CPU_CORES)\n","DEVICE = torch.device(f\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# Load data\n","if TASK in ['mimic-mortality']:\n","    train, valid, test = load_mimic_mortality(ARGS.get('data_dir'), ARGS.get('data_filename'))\n","elif TASK in ['mimic-diagnosis']:\n","    train, valid, test, diag_to_idx = \\\n","        load_mimic_diagnosis(ARGS.get('data_dir'), ARGS.get('data_filename'), ARGS.get('diag_to_idx_path'))\n","print(\"Data loaded\")\n","\n","# Create tokenizer objects\n","if MODEL_TYPE == \"electra\":\n","    tokenizer = ElectraTokenizer.from_pretrained('google/electra-small-discriminator')\n","else:\n","    # Create word index and load Fasttext embedding matrix\n","    tokenizer = FastTextTokenizer(verbose=True)\n","    tokenizer.build_word_index(train.TEXT, valid.TEXT, test.TEXT)\n","    tokenizer.build_embedding_matrix(ARGS.get('embs_path'))\n","\n","if TASK in ['mimic-mortality']:\n","    output_size = 1\n","    label_col = 'LABEL_NUM'\n","elif TASK in ['mimic-diagnosis']:\n","    output_size = len(diag_to_idx)\n","    label_col = 'DIAG'\n","\n","# Create torch Dataset objects\n","if MODEL_TYPE in [\"rnnsoft\", \"rnn\"]:\n","    if TEST:\n","        test_data = MimicDataset(test, tokenizer=tokenizer, task=TASK, label_col=label_col, output_size=output_size, device=DEVICE)\n","    else:\n","        train_data = MimicDataset(train, tokenizer=tokenizer, task=TASK, label_col=label_col, output_size=output_size, device=DEVICE)\n","        valid_data = MimicDataset(valid, tokenizer=tokenizer, task=TASK, label_col=label_col, output_size=output_size, device=DEVICE)\n","else:\n","    if TEST:\n","        test_data = HuggingfaceDataset(test, tokenizer=tokenizer, task=TASK, label_col=label_col, output_size=output_size, device=DEVICE)\n","    else:\n","        train_data = HuggingfaceDataset(train, tokenizer=tokenizer, task=TASK, label_col=label_col, output_size=output_size, device=DEVICE)\n","        valid_data = HuggingfaceDataset(valid, tokenizer=tokenizer, task=TASK, label_col=label_col, output_size=output_size, device=DEVICE)\n","print(\"Dataset created\")\n","\n","# Define network, loss function and optimizer\n","\n","\n","net = Electra(\n","    output_size=output_size,\n","    device=DEVICE,\n",")\n","if USE_PRETRAIN:\n","    net = load_model(net, ARGS.get('pretrained_model'), DEVICE)\n","\n","print('model: {}'.format(net))\n","if TASK in ['mimic-mortality', 'mimic-diagnosis']:\n","    criterion = nn.BCELoss()\n","if not TEST:\n","    optimizer = optim.Adam(net.parameters(), ARGS.get('lr'))\n","    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.2, patience=8) \\\n","        if ARGS.get('use_scheduler') else None\n","\n","# Create save directory\n","time_stamp = time.strftime(\"%m-%d-%H-%M\", time.localtime())\n","save_dir = os.path.join(EXPERIMENT_DIR, time_stamp)\n","if not os.path.exists(save_dir):\n","    os.makedirs(save_dir)\n","\n","# Save configs\n","model_desc_output = [\": \".join([str(k), str(v)]) for k, v in ARGS.items()]\n","with open(os.path.join(save_dir, 'configs.txt'), 'w') as file:\n","    file.writelines(\"\\n\".join(model_desc_output))\n","\n","if not TEST:\n","    writer = SummaryWriter(f\"runs/{TASK}/{MODEL_TYPE}-{time_stamp}\")\n","    # Train network\n","    net, logs = train_loop(\n","        net, optimizer, criterion, train_data, valid_data, save_dir=save_dir, task=TASK, n_epochs=N_EPOCHS, \\\n","            batch_size=BATCH_SIZE, verbose=True, scheduler=scheduler, save_every=ARGS.get('save_every'), \\\n","            eval_every=ARGS.get('eval_every'), writer=writer,\n","    )\n","else:\n","    # Test\n","    logs = {k: [] for k in ['test_loss', 'test_metric']}\n","    if TASK == 'mimic-diagnosis':\n","        logs['test_top_5_recall'] = []\n","        logs['test_top_30_recall'] = []\n","    test_loader = DataLoader(\n","        range(len(test)), \n","        shuffle=False, \n","        batch_size=BATCH_SIZE\n","    )\n","    if TASK == 'mimic-mortality':\n","        test_preds = predict(net, test_loader, test_data, verbose=True).cpu().numpy()\n","        np.save(os.path.join(save_dir, 'test_preds.npy'), test_preds)\n","        test_loss, test_metric = evaluate(net, test_loader, test_data, criterion, verbose=True, task=TASK)\n","    elif TASK == 'mimic-diagnosis':\n","        test_loss, test_metrics = evaluate(net, test_loader, test_data, criterion, verbose=True, task=TASK)\n","        test_metric = test_metrics['top_10_recall']\n","    print(f\"Test Loss: {test_loss:.4f} \\tTest Metric:{test_metric:.4f}\")\n","    if TASK == 'mimic-diagnosis':\n","        print(f\"Test Top 5 Recall: {test_metrics['top_5_recall']:.4f} \\tTest Top 30 Recall:{test_metrics['top_30_recall']:.4f}\")\n","    print(\"=\"*50)\n","    logs['test_loss'].append(test_loss)\n","    logs['test_metric'].append(test_metric)\n","    if TASK == 'mimic-diagnosis':\n","        logs['test_top_5_recall'].append(test_metrics['top_5_recall'])\n","        logs['test_top_30_recall'].append(test_metrics['top_30_recall'])\n","\n","# Save Model\n","if not TEST:\n","    torch.save(net.state_dict(), os.path.join(save_dir, 'model.pt'))\n","\n","# Save Logs\n","log_df = pd.DataFrame(logs)\n","log_df.to_csv(os.path.join(save_dir, 'logs.csv'))"]},{"cell_type":"code","source":[""],"metadata":{"id":"XgM867xZucu7"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"machine_shape":"hm","name":"run_nbk.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}